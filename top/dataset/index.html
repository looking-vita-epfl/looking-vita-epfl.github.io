<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1">
<meta property="og:site_name" content="LOOK dataset">
<meta property="og:type" content="article">
<meta property="og:image" content="https://looking-vita-epfl.github.io//images/background.jpg">
<meta property="twitter:image" content="https://looking-vita-epfl.github.io//images/background.jpg">
<meta name=title content>
<meta property="og:title" content>
<meta property="twitter:title" content>
<meta name=description content>
<meta property="og:description" content>
<meta property="twitter:description" content>
<meta property="twitter:card" content="summary">
<meta name=keyword content="Autonomous  Vehicles,  Computer Vision,  Deep Learning,  Eye Contact Detection">
<link rel="shortcut icon" href=/img/favicon.ico>
<title>LOOK Dataset</title>
<link rel=canonical href=/top/dataset/>
<link rel=stylesheet href=/css/iDisqus.min.css>
<link rel=stylesheet href=/css/bootstrap.min.css>
<link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css>
<link rel=stylesheet href=/css/zanshang.css>
<link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css rel=stylesheet type=text/css>
<script src=/js/jquery.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/hux-blog.min.js></script>
</head>
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
<div class=container-fluid>
<div class="navbar-header page-scroll">
<button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>LOOK dataset</a>
</div>
<div id=huxblog_navbar>
<div class=navbar-collapse>
<ul class="nav navbar-nav navbar-right">
<li>
<a href=/>Home</a>
</li>
<li><a href=/top/dataset/>DATASET</a></li>
<li><a href=/top/authors/>AUTHORS</a></li>
<li><a href=/top/github/>CODE</a></li>
<li><a href=/top/contribute/>CONTRIBUTE</a></li>
<li><a href=/top/licenses/>LICENSES</a></li>
</ul>
</div>
</div>
</div>
</nav>
<script>var $body=document.body,$toggle=document.querySelector('.navbar-toggle'),$navbar=document.querySelector('#huxblog_navbar'),$collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic);function handleMagic(a){$navbar.className.indexOf('in')>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf('in')<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script>
<header class=intro-header style=background-image:url(/images/background.jpg)>
<div class=container>
<div class=row>
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
<div class=site-heading>
<h1>LOOK dataset </h1>
<span class=subheading>Do pedestrians pay attention? Eye contact detection in the wild - official website</span>
</div>
</div>
</div>
</div>
</header>
<article>
<div class=container>
<div class=row>
<div class="col-lg-11 col-lg-offset-1
col-md-10 col-md-offset-1
post-container">
<h1 id=download-the-dataset>Download the dataset</h1>
<h2 id=automatic-download>Automatic download</h2>
<hr>
<p>Download simply everything from <a href="https://drive.google.com/file/d/1fPTU5IZQtkb1ay1rjHNFYP0ta8RvAWlc/view?usp=sharing">here</a>. [Add link to zip file of full data in google drive]</p>
<p>You want to download everything from raw data? Follow the steps here for each dataset:</p>
<p><strong>new</strong>: get the STIP annotations from <a href="https://drive.google.com/file/d/1r0R-OAlMLoGs-kOJkOnIWUWyZgV5xxWg/view?usp=sharing">this link</a></p>
<h2 id=manual-download>Manual download</h2>
<h3 id=nuscenes>Nuscenes</h3>
<hr>
<p>
<img src=/images/look/nuscenes/nu2.jpg alt="alt text">
</p>
<p>Nuscenes mainly consists of high resolution images with some crowded scenes on a traffic configuration.</p>
<h4 id=training-set>Training set</h4>
<hr>
<ul>
<li>Go to <a href=https://www.nuscenes.org/download>Nuscenes official website</a> and download the <code>sweeps</code> from <code>CAM_BACK_LEFT</code> in <code>US</code>.</li>
<li>Go to <a href=https://www.nuscenes.org/download>Nuscenes official website</a> and download the <code>samples</code> from <code>CAM_FRONT</code> in <code>US</code>.</li>
</ul>
<p>There are <em><strong>275</strong></em> images annotated from <code>US/samples/CAM_FRONT</code> and <em><strong>1500</strong></em> images from <code>US/sweeps/CAM_BACK_LEFT</code>.</p>
<h4 id=testing-set>Testing set</h4>
<hr>
<p>To write</p>
<h3 id=jrdb>JRDB</h3>
<hr>
<video id=my-player class="video-js vjs-big-play-centered" controls preload=auto poster=/img/poster.jpg data-setup={}>
<source src=/images/look/jrdb/out.mp4 type=video/mp4></source>
<source src type=video/webm></source>
<source src type=video/ogg></source>
<p class=vjs-no-js>To view this video please enable JavaScript, and consider upgrading to a web browser that <a href=http://videojs.com/html5-video-support/ target=_blank>supports HTML5 video</a></p>
</video>
<p>Download the JRDB train dataset from <a href=https://download.cs.stanford.edu/downloads/jrdb/jrdb_train.zip>here</a>.</p>
<h4 id=training-set-1>Training set</h4>
<hr>
<ul>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_0/meyer-green-2019-03-16_0</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_0/huang-lane-2019-02-12_0</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_0/clark-center-2019-02-28_0</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_0/cubberly-auditorium-2019-04-22</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_2/cubberly-auditorium-2019-04-22</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_4/cubberly-auditorium-2019-04-22</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_4/bytes-cafe-2019-02-07_0</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_8/bytes-cafe-2019-02-07_0</code></li>
</ul>
<h4 id=testing-set-1>Testing set</h4>
<hr>
<ul>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_0/nvidia-aud-2019-04-18_0</code></li>
<li><code>cvgl/group/jrdb/data/train_dataset/images/image_0/stlc-111-2019-04-19</code></li>
</ul>
<h3 id=kitti>Kitti</h3>
<hr>
<video id=my-player class="video-js vjs-big-play-centered" controls preload=auto poster=/img/poster.jpg data-setup={}>
<source src=/images/look/kitti/out.mp4 type=video/mp4></source>
<source src type=video/webm></source>
<source src type=video/ogg></source>
<p class=vjs-no-js>To view this video please enable JavaScript, and consider upgrading to a web browser that <a href=http://videojs.com/html5-video-support/ target=_blank>supports HTML5 video</a></p>
</video>
<h4 id=training-data>Training data</h4>
<p>Create an account at the Kitti Benchmark website and move to the <a href=http://www.cvlibs.net/datasets/kitti/raw_data.php>raw data</a> section. Download the <code>2011_09_29_drive_0071</code> folder.</p>
<h4 id=testing-data>Testing data</h4>
<p>Move to the 2d Object detection benchmark <a href=http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark>here</a>. Download the first folder called <code>Download left color images of object data set (12 GB)</code> or directly using this <a href=https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip>link</a>. Use the folder <code>data_object_image_2/training/image_2</code>.</p>
<h3 id=stip-dataset>STIP dataset</h3>
<p><a href="https://drive.google.com/file/d/1r0R-OAlMLoGs-kOJkOnIWUWyZgV5xxWg/view?usp=sharing">Click this link</a> to get the annotations of STIP dataset.</p>
<div id=disqus-comment></div>
</div>
<div class="col-lg-11 col-lg-offset-1
col-md-10 col-md-offset-1
sidebar-container">
</div>
</div>
</div>
</article>
<footer>
<div class=container>
<div class=row>
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
<ul class="list-inline text-center">
<li>
<a href=mailto:lookingdataset@gmail.com>
<span class="fa-stack fa-lg">
<i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
</span>
</a>
</li>
<li>
<a target=_blank href=https://github.com/vita-epfl>
<span class="fa-stack fa-lg">
<i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i>
</span>
</a>
</li>
</ul>
<p class="copyright text-muted">
Copyright &copy; LOOK dataset 2023
<br>
<a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe>
</p>
</div>
</div>
</div>
</footer>
<script>function loadAsync(f,b){var c=document,d='script',a=c.createElement(d),e=c.getElementsByTagName(d)[0];a.src=f,b&&a.addEventListener('load',function(a){b(null,a)},!1),e.parentNode.insertBefore(a,e)}</script>
<script>$('#tag_cloud').length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'}},$('#tag_cloud a').tagcloud()})</script>
<script>loadAsync("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var a=document.querySelector("nav");a&&FastClick.attach(a)})</script>
<script type=text/javascript>function generateCatalog(a){_containerSelector='div.post-container';var h=$(_containerSelector),c,d,e,f,g,b;return c=h.find('h1,h2,h3,h4,h5,h6'),$(a).html(''),c.each(function(){d=$(this).prop('tagName').toLowerCase(),g="#"+$(this).prop('id'),e=$(this).text(),b=$('<a href="'+g+'" rel="nofollow">'+e+'</a>'),f=$('<li class="'+d+'_nav"></li>').append(b),$(a).append(f)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(a){a.preventDefault(),$('.side-catalog').toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$('.catalog-body').onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script>
</body>
</html>